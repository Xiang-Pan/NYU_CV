{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad74cb38-0570-496c-ab42-bad570eca27a",
   "metadata": {},
   "source": [
    "# task_datasets.cv_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1d9efe0-19ed-466c-8b25-f94f4084d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from utils import *\n",
    "from randaugment import RandAugment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b307d9-8999-42a9-ace2-2d9d569dab69",
   "metadata": {},
   "source": [
    "## CVDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49df65a6-68d8-4029-a7cf-c0129e8d1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVDataset(Dataset):\n",
    "    def __init__(self, split, transform=None):\n",
    "        self.split = split\n",
    "        if split in [\"train\",\"validation\"]:\n",
    "            path = \"cached_datasets/\"+split+\"/\"\n",
    "            X_path = path + \"X.pt\"\n",
    "            y_path = path + \"y.pt\"\n",
    "            self.X = torch.load(X_path).squeeze(1)\n",
    "            self.y = torch.load(y_path).squeeze(1)\n",
    "            print(self.X.shape)\n",
    "        elif split == \"testing\":\n",
    "            path = \"cached_datasets/\"+split+\"/\"\n",
    "            X_path = path + \"test.pt\"\n",
    "            self.X = torch.load(X_path).squeeze(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split\")\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.split != \"testing\":\n",
    "            if self.transform:\n",
    "                return self.transform(self.X[idx]), self.y[idx]\n",
    "            else:\n",
    "                return self.X[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25ac12b-1f2d-4695-ab11-f99a827783f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_dataloader(batch_size = 32, augument = False):\n",
    "    if augument:\n",
    "        train_dataset = torch.utils.data.ConcatDataset\\\n",
    "                    (\n",
    "                        [\n",
    "                            CVDataset(\"train\", transform=None),\n",
    "                            # CVDataset(\"train\", transform=data_random_aug),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.ColorJitter(brightness=5),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.ColorJitter(saturation=5),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.ColorJitter(contrast=5),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.ColorJitter(hue=0.4),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.RandomRotation(15),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.RandomHorizontalFlip(1),transforms.RandomVerticalFlip(1),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.Grayscale(num_output_channels=3),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.RandomAffine(degrees=15, translate=(0.1,0.1)),])),\n",
    "                            CVDataset(\"train\", transform=transforms.Compose([transforms.RandomAffine(degrees=15, shear=2),])),\n",
    "                        ]\n",
    "                    )\n",
    "        val_dataset = CVDataset(\"validation\", transform=None)\n",
    "        test_dataset = CVDataset(\"testing\", transform=None)\n",
    "    else:\n",
    "        train_dataset, val_dataset, test_dataset = get_cv_dataset(batch_size)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4,)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af54bfa-a0e2-4838-8179-140d2d9d12e3",
   "metadata": {},
   "source": [
    "**Findings: If we add all the data augumentaion/data transform together, which may leed to high noise and inconsistent training process.**\n",
    "\n",
    "**Data Augumentaion**\n",
    "I tried both the training time data augumentation and [test time data augumentaion](https://arxiv.org/pdf/2011.11156.pdf). In such task, test time data augumentaion may harm the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81716c-91a0-4a2e-a29a-94ddd16e7586",
   "metadata": {},
   "source": [
    "# option.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b71f536-fc8c-4cea-8a69-0a60e3bbfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def str2bool(str):\n",
    "    return True if str.lower() == 'true' else False\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',           type=str,    default=None,       required=False,)\n",
    "parser.add_argument('--learning_rate',  type=float,  default=0.01,       required=False,)\n",
    "parser.add_argument('--batch_size',     type=int,    default=32,         required=False,)\n",
    "parser.add_argument('--warmup_epochs',  type=int,    default=-1,         required=False,)\n",
    "parser.add_argument('--max_epochs',     type=int,    default=80,         required=False,)\n",
    "parser.add_argument('--backbone_name',  type=str,    default=\"TfmNet\",   required=False,)\n",
    "parser.add_argument('--scheduler_name', type=str,    default=\"cosine\",       required=False,)\n",
    "parser.add_argument('--optimizer_name', type=str,    default=\"adam\",     required=False,)\n",
    "parser.add_argument('--weight_decay',   type=float,  default=1e-5,       required=False,)\n",
    "parser.add_argument('--aug',            action='store_true',             default=True,)\n",
    "parser.add_argument('--mixup',          action='store_true',             default=False,)\n",
    "parser.add_argument('--label_smoothing',type=float,  default=False,)\n",
    "parser.add_argument('--focal_loss',     action='store_true',             default=False,)\n",
    "parser.add_argument('--seed',           type=int,             default=1)\n",
    "parser.add_argument('--sweep_aug',      type=int,             default=0)\n",
    "\n",
    "def get_option():\n",
    "    option = parser.parse_args(args = [])\n",
    "    return option\n",
    "option = get_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d4b2d7-da81-4c39-bd90-f97eb643259c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(aug=True, backbone_name='TfmNet', batch_size=32, focal_loss=False, label_smoothing=False, learning_rate=0.01, max_epochs=80, mixup=False, name=None, optimizer_name='adam', scheduler_name='cosine', seed=1, sweep_aug=0, warmup_epochs=-1, weight_decay=1e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1070c1-0d63-44b0-8982-e1d7a2270f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nets import NET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import ttach as tta\n",
    "\n",
    "# from task_datasets.cv_datasets import get_cv_dataloader\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from utils import *\n",
    "from option import *\n",
    "from warmup_scheduler import GradualWarmupScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1302d-4bf6-44c4-b86a-6858a2c619e3",
   "metadata": {},
   "source": [
    "# nets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3be183-4994-48d9-a2ef-8481df09569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NET(nn.Module):\n",
    "    def __init__(self, backbone_name = \"ResNet18\", num_classes = 2, pretrained = False):\n",
    "        super(NET, self).__init__()\n",
    "        if backbone_name == \"ResNet12\":\n",
    "            self.backbone = ResNet12(pretrained = pretrained, num_classes= num_classes)\n",
    "        elif backbone_name == \"ResNet18\":\n",
    "            self.backbone = ResNet18(pretrained = pretrained, num_classes= num_classes)\n",
    "        elif backbone_name == \"ResNet50\":\n",
    "            self.backbone = ResNet50(pretrained = pretrained, num_classes= num_classes)\n",
    "        elif backbone_name == \"LeNet5\":\n",
    "            self.backbone = LeNet5()\n",
    "        elif backbone_name == \"LaNet\":\n",
    "            self.backbone = LaNet()\n",
    "        elif backbone_name == \"SampleNet\":\n",
    "            self.backbone = SampleNet()\n",
    "        elif backbone_name == \"KaggleNet\":\n",
    "            self.backbone = KaggleNet()\n",
    "        elif backbone_name == \"EfficientNet\":\n",
    "            self.backbone = EfficientNet.from_name('efficientnet-b0', image_size=(32,32), num_classes=num_classes)\n",
    "        elif backbone_name == \"vgg16\":\n",
    "            self.backbone = vgg16(pretrained = pretrained, num_classes= num_classes)\n",
    "        elif backbone_name == \"inception_v3\":\n",
    "            self.backbone = models.inception_v3(pretrained = pretrained, aux_logits = True)\n",
    "            self.backbone.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            self.backbone.fc = nn.Linear(2048, num_classes)\n",
    "            print(self.backbone)\n",
    "        elif backbone_name == \"TfmNet\":\n",
    "            self.backbone = TfmNet(num_classes=num_classes)\n",
    "        elif backbone_name == \"TfmNetHighway\":\n",
    "            self.backbone = TfmNetHighway(num_classes=num_classes)\n",
    "        else:\n",
    "            raise Exception(\"backbone name error\")\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    # def get_feature(self, x):\n",
    "    #     return self.backbone.get_feature(x)\n",
    "    # def forward_with_feature(self, x):\n",
    "    #     return self.backbone.forward_with_feature(x)\n",
    "    # def forward_with_layer2(self, x):\n",
    "    #     return self.backbone.forward_with_layer2(x)\n",
    "    # def forward_from_layer2(self, layer2_x):\n",
    "    #     return self.backbone.forward_from_layer2(layer2_x)\n",
    "    # def forward_from_layer2_with_feature(self, layer2_x):\n",
    "    #     return self.backbone.forward_from_layer2_with_feature(layer2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9fb4ea-e490-44fd-94c4-217620911963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, n_classes=43):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9368648-f48b-40ca-abf3-73ae0e7c96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, pretrained=False, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "        self.model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logit = self.model(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe0d259-64e2-4de2-bd69-5b4d00d5e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer\tShape\n",
    "# Input\t32x32x3\n",
    "# Convolution (valid, 5x5x6)\t28x28x6\n",
    "# Max Pooling (valid, 2x2)\t14x14x6\n",
    "# Activation (ReLU)\t14x14x6\n",
    "# Convolution (valid, 5x5x16)\t10x10x16\n",
    "# Max Pooling (valid, 2x2)\t5x5x16\n",
    "# Activation (ReLU)\t5x5x16\n",
    "# Flatten\t400\n",
    "# Dense\t120\n",
    "# Activation (ReLU)\t120\n",
    "# Dense\t43\n",
    "# Activation (Softmax)\t43\n",
    "class LaNet(nn.Module):\n",
    "    def __init__(self, pretrained=False, num_classes=43):\n",
    "        super(LaNet, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=400, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(in_features=120, out_features=num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature = self.feature_extractor(x)\n",
    "        logit = self.classifier(feature)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e75592-7852-4ecc-8177-a947ee5ba2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfmNet(nn.Module):\n",
    "    def __init__(self, num_classes=43):\n",
    "        super(TfmNet, self).__init__()\n",
    "        \n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 100, kernel_size=5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.Dropout2d(0.5)\n",
    "        )\n",
    "\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(100, 150, kernel_size=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(150),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(150),\n",
    "            nn.Dropout2d(0.5)\n",
    "        )\n",
    "        \n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 250, kernel_size=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(250),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(250),\n",
    "            nn.Dropout2d(0.5)\n",
    "        )\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "        \n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 4 * 4, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "        \n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "        self.fc1 = nn.Linear(1000, 350)\n",
    "        self.fc1_relu = nn.ReLU()\n",
    "        self.fc1_dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(350, num_classes)\n",
    "\n",
    "    def stn1(self, x):\n",
    "        xs = self.localization(x)\n",
    "        # print(xs.shape, \"xs\") \n",
    "        xs = xs.view(-1, 10 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=True)\n",
    "        x = F.grid_sample(x, grid, align_corners=True)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn1(x)\n",
    "\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.c3(x)\n",
    "        \n",
    "        x = x.view(-1, 250 * 2 * 2)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_relu(x)\n",
    "        x = self.fc1_dropout(x)\n",
    "        \n",
    "        logit = self.fc2(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f389ba8-0923-4596-9062-a54a74540bd6",
   "metadata": {},
   "source": [
    "# wandb_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e421bca-94d8-4f47-9bb2-66bd389b9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiang-pan\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-09-30 21:04:32.548165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lucky-fog-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/xiang-pan/assignment1_2_submission\" target=\"_blank\">https://wandb.ai/xiang-pan/assignment1_2_submission</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/xiang-pan/assignment1_2_submission/runs/1xt89um3\" target=\"_blank\">https://wandb.ai/xiang-pan/assignment1_2_submission/runs/1xt89um3</a><br/>\n",
       "                Run data is saved locally in <code>/home/xiangpan/Labs/NYU_CV/Assignment/Assignment1_2/wandb/run-20210930_210431-1xt89um3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1xt89um3)</h1><iframe src=\"https://wandb.ai/xiang-pan/assignment1_2_submission/runs/1xt89um3\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0fdfa74a00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"assignment1_2_submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1c3a6",
   "metadata": {},
   "source": [
    "# Please check the training log below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c763ff-9029-4e58-931f-b84834f48b02",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138c13e2-f27b-41c4-a2fd-2e6f6f2118f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from kornia.losses import focal_loss \n",
    "\n",
    "class LossWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossWrapper, self).__init__()\n",
    "        print(\"focal_loss\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return focal_loss(input, target, alpha=0.5, gamma=2.0, reduction='mean')\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        \"\"\"\n",
    "        Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212b8dc-4ab2-4783-b001-7a61f3cd87ce",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e88e52af-470c-4077-be85-4d33dd3d5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, args):\n",
    "    scheduler_name = args.scheduler_name\n",
    "    if scheduler_name == 'cosine':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.max_epochs-args.warmup_epochs)\n",
    "    elif scheduler_name == 'exp':\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.90)\n",
    "    elif scheduler_name == 'step':\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, gamma=0.1, milestones=[7])\n",
    "    elif scheduler_name == 'ReduceLROnPlateau':\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')\n",
    "        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5,factor=0.5,verbose=True)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=5,factor=0.5,verbose=True)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    if scheduler is not None:\n",
    "        if args.warmup_epochs > 0:\n",
    "            scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=args.warmup_epochs, after_scheduler=scheduler)\n",
    "            return scheduler\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06571216-bba8-4043-89f7-7b828ce48370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_epochs, model, optimizer, train_loader, val_loader, test_loader, args):\n",
    "    \n",
    "    max_train_acc = 0\n",
    "    max_val_acc = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    optimizer.step()\n",
    "    if args.focal_loss:\n",
    "        criterion = LossWrapper()\n",
    "    elif args.label_smoothing > 0:\n",
    "        criterion = LabelSmoothing(smoothing=args.label_smoothing)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer, args)\n",
    "    \n",
    "    for cur_epoch in range(0, max_epochs):\n",
    "        # scheduler_warmup.step(cur_epoch)\n",
    "        # train\n",
    "        model.train()\n",
    "        train_acc_metric = torchmetrics.Accuracy().cuda()\n",
    "        train_acc_metric.reset()\n",
    "        train_loss_epoch = 0\n",
    "        val_loss_epoch = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            output = model(data)\n",
    "            train_loss = criterion(output, target)\n",
    "            train_loss_epoch += train_loss.item()\n",
    "            \n",
    "            preds = output.softmax(dim=-1)\n",
    "            acc = train_acc_metric(preds, target).cuda()\n",
    "            \n",
    "            wandb.log({'train_loss': train_loss})\n",
    "            wandb.log({'train_acc': acc})\n",
    "\n",
    "            if args.mixup:\n",
    "                if cur_epoch > args.warmup_epochs:\n",
    "                    mixed_x, y_a, y_b, lam = mixup_data(data, target)\n",
    "                    mixed_pred = model(mixed_x)\n",
    "                    mixup_loss = mixup_criterion(criterion, mixed_pred, y_a, y_b, lam)\n",
    "                    train_loss += mixup_loss\n",
    "                    wandb.log({'mixup_train_loss': mixup_loss.item()})\n",
    "                \n",
    "            \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_acc = train_acc_metric.compute()\n",
    "        wandb.log({'train_acc_epoch': train_acc, \"epoch\": cur_epoch})\n",
    "        wandb.log({'train_loss_epoch': train_loss_epoch/len(train_loader), \"epoch\": cur_epoch})\n",
    "        max_train_acc = max(max_train_acc, train_acc)\n",
    "        wandb.log({'max_train_acc': max_train_acc, \"epoch\": cur_epoch})\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        val_acc_metric = torchmetrics.Accuracy().cuda()\n",
    "        val_acc_metric.reset()\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            \n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            output = model(data)\n",
    "\n",
    "            val_loss = F.cross_entropy(output, target)\n",
    "            val_loss_epoch += val_loss.item()\n",
    "            preds = output.softmax(dim=-1)\n",
    "            acc = val_acc_metric(preds, target).cuda()\n",
    "            wandb.log({'val_loss': val_loss})\n",
    "            wandb.log({'val_acc': acc})\n",
    "        val_acc = val_acc_metric.compute()\n",
    "        wandb.log({'val_acc_epoch': val_acc, \"epoch\": cur_epoch})\n",
    "        wandb.log({'val_loss_epoch': val_loss_epoch/len(val_loader), \"epoch\": cur_epoch})\n",
    "        max_val_acc = max(max_val_acc, val_acc)\n",
    "        wandb.log({'mac_val_acc': max_val_acc, \"epoch\": cur_epoch})\n",
    "        \n",
    "        \n",
    "        # predict test data\n",
    "        path = \"./outputs/\"+wandb.run.id\n",
    "        if not os.path.exists(path):\n",
    "            os.system(\"mkdir -p %s\" % path)\n",
    "        outfile_name = path+\"/\"+str(cur_epoch)+\".csv\"\n",
    "        model_name = path+\"/\"+str(cur_epoch)+\".pt\"\n",
    "\n",
    "        output_file = open(outfile_name, \"w\")\n",
    "        \n",
    "        # dataframe_dict = {\"Filename\" : [], \"ClassId\": []}\n",
    "        df = pd.DataFrame(columns=['Filename', 'ClassId'])\n",
    "        file_ids = pickle.load(open('./cached_datasets/testing/file_ids.pkl', 'rb'))\n",
    "        \n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "    \n",
    "            data = data.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output.softmax(dim=-1), dim = -1).cpu().detach().tolist()\n",
    "            \n",
    "            file_id = file_ids[batch_idx*args.batch_size:(batch_idx+1)*args.batch_size]\n",
    "            dft = pd.DataFrame(columns=['Filename', 'ClassId'], data=list(zip(file_id, preds)))\n",
    "            df = df.append(dft, ignore_index=True)\n",
    "\n",
    "        df.to_csv(outfile_name, index=False)\n",
    "        print(\"Written to csv file {}\".format(outfile_name))\n",
    "        torch.save(model, model_name)\n",
    "        \n",
    "        \n",
    "        if scheduler is not None:\n",
    "            if scheduler.__class__.__name__ == 'ReduceLROnPlateau':\n",
    "                # scheduler.step(val_acc)\n",
    "                scheduler.step(np.around(val_acc.cpu().numpy(), decimals=2))\n",
    "                wandb.log({'learning_rate': optimizer.param_groups[0]['lr'], \"epoch\": cur_epoch})\n",
    "            else:\n",
    "                scheduler.step(cur_epoch)\n",
    "                wandb.log({'learning_rate': scheduler.get_last_lr(), \"epoch\": cur_epoch})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8f6a026-f478-4448-ba4c-b031ee1af5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auto_name(args):\n",
    "    if args.scheduler_name is None:\n",
    "        scheduler_name = 'None'\n",
    "    else:\n",
    "        scheduler_name = args.scheduler_name\n",
    "    auto_name = '_'.join([  args.backbone_name,\n",
    "                            scheduler_name,\n",
    "                            str(args.learning_rate),\n",
    "                            str(args.max_epochs),\n",
    "                            str(args.batch_size),\n",
    "                            str(args.warmup_epochs),\n",
    "                            str(args.weight_decay),\n",
    "                            str(args.label_smoothing),\n",
    "                            args.optimizer_name\n",
    "                        ])\n",
    "    return auto_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b924265-66f7-478c-b508-164ee5b69747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_args(args):\n",
    "    # python main.py --backbone_name=TfmNet --batch_size=64 --learning_rate=0.0005 --max_epochs=100 --weight_decay=0 --scheduler=cosine --warmup_epochs=5 --aug --optimizer_name=adam --seed 1 --label_smoothing=0.01 --sweep_aug=1 --name=debug\n",
    "    args.backbone_name = \"TfmNet\"\n",
    "    args.batch_size = 64\n",
    "    args.learning_rate = 0.005\n",
    "    args.max_epochs = 100\n",
    "    args.weight_decay = 0\n",
    "    args.scheduler = \"cosine\"\n",
    "    args.warmup_epochs = 5\n",
    "    args.optimizer_name = \"adam\"\n",
    "    args.seed = 1\n",
    "    args.label_smoothing = 0.01\n",
    "    args.sweep_aug = 1\n",
    "    args.name = \"submission\"\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85775daa-e62d-4dae-9460-ce4ad33f8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # args = get_option()\n",
    "    args = set_args(option)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.name is None:\n",
    "        wandb.run.name = get_auto_name(args)\n",
    "    else:\n",
    "        wandb.run.name = args.name\n",
    "    \n",
    "    nclasses = 43 # GTSRB has 43 classes\n",
    "    model = NET(backbone_name=args.backbone_name, num_classes=43, pretrained=False)\n",
    "    model.apply(weight_init)\n",
    "    # model = tta.ClassificationTTAWrapper(model, tta.aliases.d4_transform(), merge_mode='tsharpen')\n",
    "    model = model.cuda()\n",
    "    if args.optimizer_name == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    elif args.optimizer_name == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=args.weight_decay)\n",
    "    # no_decay = list()\n",
    "    # decay = list()\n",
    "    # for m in model.modules():\n",
    "    #     if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "    #         decay.append(m.weight)\n",
    "    #         no_decay.append(m.bias)\n",
    "    #     elif hasattr(m, 'weight'):\n",
    "    #         no_decay.append(m.weight)\n",
    "    #     elif hasattr(m, 'bias'):\n",
    "    #         no_decay.append(m.bias)\n",
    "\n",
    "    if args.sweep_aug == 1:\n",
    "        args.aug = True\n",
    "    else:\n",
    "        args.aug = False\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_cv_dataloader(batch_size = args.batch_size, augument=args.aug)\n",
    "    train(args.max_epochs, model, optimizer, train_dataloader, val_dataloader, test_dataloader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87697d3c-5521-44a3-a7b2-677c21bde98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([35339, 3, 32, 32])\n",
      "torch.Size([3870, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:572: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.object, string),\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:573: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.bool, bool),\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING: np.object,\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:601: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL: np.bool,\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:618: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING_REF: np.object,\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:623: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL_REF: np.bool,\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:113: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:114: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to csv file ./outputs/1xt89um3/0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangpan/.conda/envs/pl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2733725/2453735964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moption\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradualWarmupScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2733725/100087994.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cv_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2733725/4150740178.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(max_epochs, model, optimizer, train_loader, val_loader, test_loader, args)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from nets import NET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import ttach as tta\n",
    "# from task_datasets.cv_datasets import get_cv_dataloader\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from utils import *\n",
    "from option import *\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323513e-f062-4b0d-9933-a3ad11dcebdc",
   "metadata": {},
   "source": [
    "The kernel died after 54 epochs (which may be caused by the notebook environment). I pasted the partial training log below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d568a1e-abd1-4869-8f68-466c76b17ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "team, project, run_id = \"xiang-pan\", \"assignment1_2_submission\", \"2zdy4mui\"\n",
    "run = api.run(f\"{team}/{project}/{run_id}\")\n",
    "metrics_dataframe = run.history()\n",
    "\n",
    "display()  # you may need to zoom out to see the whole window!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7345c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/xiang-pan/assignment1_2_submission/runs/7teg2ng5?workspace=user-xiang-pan\" width=\"1200\" height=\"1000\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://wandb.ai/xiang-pan/assignment1_2_submission/runs/7teg2ng5?workspace=user-xiang-pan\" width=\"1200\" height=\"1000\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198af7d-8794-4f68-94f0-c81fcbf1b4db",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f7d77-32b8-47f5-8deb-36d8e917921e",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530960a3-c4db-4d22-9a50-b5c1763a28f1",
   "metadata": {},
   "source": [
    "In this experiment, I tried much architecture along with their training tricks.\n",
    "\n",
    "\n",
    "### LeNet5 and its modification\n",
    "The simple LeNet5 can achieve the baseline above result but is limited to its model capacity, there is a gap between its accuracy and SOTA.\n",
    "\n",
    "### ResNet 18\n",
    "ResNet18 makes training loss quickly drop. However, the validation loss is still high and hard to converge.\n",
    "\n",
    "### Spatical Transformer + Convolution\n",
    "Refer to [Deep neural network for traffic sign recognition systems: An analysis of spatial transformers and stochastic optimisation methods](https://pubmed.ncbi.nlm.nih.gov/29427842/), the spatical transformer(stn) before the convolution and between the convolution works. Due the training data limited and smaller cropped image size, I only add the tfm layer before general convolution.\n",
    "\n",
    "The architecture can be represented as s1_c_c_c in that paper.\n",
    "\n",
    "Some of the code refer to [spatial_transformer_tutorial](https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)\n",
    "\n",
    "#### Network Architecture Search\n",
    "I used wandb for simple NAS by changing the hidden layer size or the convolution layer kernel parameter, I used a normarl setting cloest the search result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d30a501-265f-4985-a488-34b20d113dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]           1,184\n",
      "         MaxPool2d-2            [-1, 8, 13, 13]               0\n",
      "              ReLU-3            [-1, 8, 13, 13]               0\n",
      "            Conv2d-4             [-1, 10, 9, 9]           2,010\n",
      "         MaxPool2d-5             [-1, 10, 4, 4]               0\n",
      "              ReLU-6             [-1, 10, 4, 4]               0\n",
      "            Linear-7                   [-1, 32]           5,152\n",
      "              ReLU-8                   [-1, 32]               0\n",
      "            Linear-9                    [-1, 6]             198\n",
      "           Conv2d-10          [-1, 100, 28, 28]           7,600\n",
      "        LeakyReLU-11          [-1, 100, 28, 28]               0\n",
      "      BatchNorm2d-12          [-1, 100, 28, 28]             200\n",
      "        MaxPool2d-13          [-1, 100, 14, 14]               0\n",
      "      BatchNorm2d-14          [-1, 100, 14, 14]             200\n",
      "        Dropout2d-15          [-1, 100, 14, 14]               0\n",
      "           Conv2d-16          [-1, 150, 12, 12]         135,150\n",
      "        LeakyReLU-17          [-1, 150, 12, 12]               0\n",
      "      BatchNorm2d-18          [-1, 150, 12, 12]             300\n",
      "        MaxPool2d-19            [-1, 150, 6, 6]               0\n",
      "      BatchNorm2d-20            [-1, 150, 6, 6]             300\n",
      "        Dropout2d-21            [-1, 150, 6, 6]               0\n",
      "           Conv2d-22            [-1, 250, 4, 4]         337,750\n",
      "        LeakyReLU-23            [-1, 250, 4, 4]               0\n",
      "      BatchNorm2d-24            [-1, 250, 4, 4]             500\n",
      "        MaxPool2d-25            [-1, 250, 2, 2]               0\n",
      "      BatchNorm2d-26            [-1, 250, 2, 2]             500\n",
      "        Dropout2d-27            [-1, 250, 2, 2]               0\n",
      "           Linear-28                  [-1, 350]         350,350\n",
      "             ReLU-29                  [-1, 350]               0\n",
      "          Dropout-30                  [-1, 350]               0\n",
      "           Linear-31                   [-1, 43]          15,093\n",
      "================================================================\n",
      "Total params: 856,487\n",
      "Trainable params: 856,487\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.05\n",
      "Params size (MB): 3.27\n",
      "Estimated Total Size (MB): 6.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = TfmNet().cuda()\n",
    " \n",
    "summary(model, (3, 32, 32))\n",
    "# -1 represent the batch size here"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c3723bd-bfb0-43ad-ae00-7303f294e2ae",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1            [-1, 8, 26, 26]           1,184\n",
    "         MaxPool2d-2            [-1, 8, 13, 13]               0\n",
    "              ReLU-3            [-1, 8, 13, 13]               0\n",
    "            Conv2d-4             [-1, 10, 9, 9]           2,010\n",
    "         MaxPool2d-5             [-1, 10, 4, 4]               0\n",
    "              ReLU-6             [-1, 10, 4, 4]               0\n",
    "            Linear-7                   [-1, 32]           5,152\n",
    "              ReLU-8                   [-1, 32]               0\n",
    "            Linear-9                    [-1, 6]             198\n",
    "           Conv2d-10          [-1, 100, 28, 28]           7,600\n",
    "        LeakyReLU-11          [-1, 100, 28, 28]               0\n",
    "      BatchNorm2d-12          [-1, 100, 28, 28]             200\n",
    "        MaxPool2d-13          [-1, 100, 14, 14]               0\n",
    "      BatchNorm2d-14          [-1, 100, 14, 14]             200\n",
    "        Dropout2d-15          [-1, 100, 14, 14]               0\n",
    "           Conv2d-16          [-1, 150, 12, 12]         135,150\n",
    "        LeakyReLU-17          [-1, 150, 12, 12]               0\n",
    "      BatchNorm2d-18          [-1, 150, 12, 12]             300\n",
    "        MaxPool2d-19            [-1, 150, 6, 6]               0\n",
    "      BatchNorm2d-20            [-1, 150, 6, 6]             300\n",
    "        Dropout2d-21            [-1, 150, 6, 6]               0\n",
    "           Conv2d-22            [-1, 250, 4, 4]         337,750\n",
    "        LeakyReLU-23            [-1, 250, 4, 4]               0\n",
    "      BatchNorm2d-24            [-1, 250, 4, 4]             500\n",
    "        MaxPool2d-25            [-1, 250, 2, 2]               0\n",
    "      BatchNorm2d-26            [-1, 250, 2, 2]             500\n",
    "        Dropout2d-27            [-1, 250, 2, 2]               0\n",
    "           Linear-28                  [-1, 350]         350,350\n",
    "             ReLU-29                  [-1, 350]               0\n",
    "          Dropout-30                  [-1, 350]               0\n",
    "           Linear-31                   [-1, 43]          15,093\n",
    "================================================================\n",
    "Total params: 856,487\n",
    "Trainable params: 856,487\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.01\n",
    "Forward/backward pass size (MB): 3.05\n",
    "Params size (MB): 3.27\n",
    "Estimated Total Size (MB): 6.33\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109ed3e-518b-4148-8c1d-6442d687990d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Trciks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1729dea-202f-4bd2-8828-404f7d97e308",
   "metadata": {},
   "source": [
    "### Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40884ea8-4e2c-42b2-b411-1b3995b70394",
   "metadata": {},
   "source": [
    "[Regularizing Neural Networks by Penalizing Confident Output Distributions](https://arxiv.org/abs/1701.06548) proposed that model is too confident may harm the generalization, and we can penalize such behavior by giving a soft label.\n",
    "\n",
    "I used \\lamda = 0.01 here, the best searched result is 0.0097.......\n",
    "\n",
    "**NOTE:** Because we used the label smoothing, it maybe hard to get high training accuracy and lead to high training loss, but the validation performance is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3b4a6-8d97-4960-bfc2-e23a938d9568",
   "metadata": {},
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d01edb-2c2c-4092-88d1-510920add490",
   "metadata": {},
   "source": [
    "[Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002v2) Focal loss applies a modulating term to the cross entropy loss in order to focus learning on hard negative examples. This method does not work in my network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ce3ba-de89-4ff4-bdb8-5a9af6fda943",
   "metadata": {},
   "source": [
    "### Other training tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf990b-5c71-4801-a882-762a5badf615",
   "metadata": {},
   "source": [
    "[Bag of Tricks for Image Classiﬁcation with Convolutional Neural Networks](https://arxiv.org/abs/1812.01187)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb02fe-101f-4118-8beb-4a4e87eeb865",
   "metadata": {},
   "source": [
    "## Data Augumentaion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe021301-a0d3-4dd4-8b8b-20c0d63857e9",
   "metadata": {},
   "source": [
    "I tried the data augmentation in torchvision.transforms. One trick here is not to add all the data augmentation together, but to use them one by one and get an augmented dataset.\n",
    "\n",
    "__all__ = [\"Compose\", \"ToTensor\", \"PILToTensor\", \"ConvertImageDtype\", \"ToPILImage\", \"Normalize\", \"Resize\", \"Scale\",\n",
    "           \"CenterCrop\", \"Pad\", \"Lambda\", \"RandomApply\", \"RandomChoice\", \"RandomOrder\", \"RandomCrop\",\n",
    "           \"RandomHorizontalFlip\", \"RandomVerticalFlip\", \"RandomResizedCrop\", \"RandomSizedCrop\", \"FiveCrop\", \"TenCrop\",\n",
    "           \"LinearTransformation\", \"ColorJitter\", \"RandomRotation\", \"RandomAffine\", \"Grayscale\", \"RandomGrayscale\",\n",
    "           \"RandomPerspective\", \"RandomErasing\", \"GaussianBlur\", \"InterpolationMode\", \"RandomInvert\", \"RandomPosterize\",\n",
    "           \"RandomSolarize\", \"RandomAdjustSharpness\", \"RandomAutocontrast\", \"RandomEqualize\"]\n",
    "           \n",
    "Here is the supported transform list in torchvision, I tried those with less harm to the image, for the reason that the small image size and limited dataset size which may not support too large pertubation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764681f7-3f9c-4858-8c86-86cbd62841af",
   "metadata": {},
   "source": [
    "I tried AutoAugmentation and RandomAugumentaion in torchvision-main, no much improvment if we already have almost the genreral augumentaion methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b2e841-b589-4383-987e-b77db21fdd9d",
   "metadata": {},
   "source": [
    "#### [Test Time Data Augumentaion](https://arxiv.org/pdf/2011.11156.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9882d1d-859b-48ae-a9e6-9b62c7f6d000",
   "metadata": {},
   "source": [
    "We can augment the test samples while predicting, and using their aggregated results(e.g. vote) as the final prediction. In this task, this method does not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a286f-2f96-4e78-b7b4-719b4fe66edd",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f521f09-5281-4e00-bfb6-40ce5906d367",
   "metadata": {},
   "source": [
    "### wandb sweep search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbcf20-fbe0-4ad4-8cab-d2e7be17ad77",
   "metadata": {},
   "source": [
    "I used wandb for hyperparameter tuning with the config below."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f406d73-455f-4935-bb21-724c3a66bb66",
   "metadata": {},
   "source": [
    "program: main.py\n",
    "method: bayes \n",
    "metric:\n",
    "  name: val_acc\n",
    "  goal: maximize\n",
    "parameters:\n",
    "  learning_rate:\n",
    "    max: 0.001\n",
    "    min: 0.0003\n",
    "  batch_size:\n",
    "    values: [32, 64, 128, 256, 512]\n",
    "  warmup_epochs:\n",
    "    min: 1\n",
    "    max: 8\n",
    "  max_epochs:\n",
    "    min: 100\n",
    "    max: 150\n",
    "  label_smoothing:\n",
    "    min: 0.006\n",
    "    max: 0.012 \n",
    "  weight_decay:\n",
    "    min: 0.0\n",
    "    max: 0.0001\n",
    "  sweep_aug:\n",
    "    values: [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733747d6-97a5-4d49-bf47-19a2f7a1d754",
   "metadata": {},
   "source": [
    "The search result is around the hyperparameter config I used above, I just round the float32 result into a more normal one. The result here may different from the best result I submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08d2bb-5cbb-4e83-b5ce-7989c6b0cf57",
   "metadata": {},
   "source": [
    "### optimizer\n",
    "\n",
    "Adam is a general optimizer and suitable for most cases, we can get better performance by adjust the learning rate by multisetp scheduler for SGD, but it may be sensitive if the trainining process is not so smooth and robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc0a30-fe02-4bc2-8063-fc4828a9b750",
   "metadata": {},
   "source": [
    "### Scheduler\n",
    "I used the **CosineAnnealingLR**, which decreases the learning rate following cosine annealing schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31120de4-35be-4270-825a-b6435e697456",
   "metadata": {},
   "source": [
    "I used warmup in the scheduler with warmup_epochs = 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
